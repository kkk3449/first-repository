{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "rolled-bridge",
   "metadata": {},
   "source": [
    "### Step 1. 데이터 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "charitable-sailing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기: 187088\n",
      "Examples:\n",
      " [' There must be some kind of way outta here', 'Said the joker to the thief', \"There's too much confusion\"]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import re                  # 정규표현식을 위한 Regex 지원 모듈 (문장 데이터를 정돈하기 위해) \n",
    "import numpy as np         # 변환된 문장 데이터(행렬)을 편하게 처리하기 위해\n",
    "import tensorflow as tf    # 대망의 텐서플로우!\n",
    "\n",
    "txt_file_path = os.getenv('HOME')+'/aiffel/lyricist/data/lyrics/*'\n",
    "\n",
    "txt_list = glob.glob(txt_file_path)\n",
    "\n",
    "raw_corpus = []\n",
    "\n",
    "# 여러개의 txt 파일을 모두 읽어서 raw_corpus 에 담습니다.\n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        raw = f.read().splitlines()\n",
    "        raw_corpus.extend(raw)\n",
    "\n",
    "print(\"데이터 크기:\", len(raw_corpus))\n",
    "print(\"Examples:\\n\", raw_corpus[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raising-ending",
   "metadata": {},
   "source": [
    "### Step 2. 데이터 정제\n",
    "나만의 방법으로 데이터 정제를 해보았다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "careful-lafayette",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> this is sample sentence . <end>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()       # 소문자로 바꾸고 양쪽 공백을 삭제\n",
    "  \n",
    "    # 아래 3단계를 거쳐 sentence는 스페이스 1개를 delimeter로 하는 소문자 단어 시퀀스로 바뀝니다.\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)        # 패턴의 특수문자를 만나면 특수문자 양쪽에 공백을 추가\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)                  # 공백 패턴을 만나면 스페이스 1개로 치환\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence)  # a-zA-Z?.!,¿ 패턴을 제외한 모든 문자(공백문자까지도)를 스페이스 1개로 치환\n",
    "    #sentence.split()\n",
    "    \n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    sentence = '<start> ' + sentence + ' <end>'      # 이전 스텝에서 본 것처럼 문장 앞뒤로 <start>와 <end>를 단어처럼 붙여 줍니다\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "print(preprocess_sentence(\"This @_is ;;;sample        sentence.\"))   # 이 문장이 어떻게 필터링되는지 확인해 보세요.\n",
    "#print(len(preprocess_sentence(\"This @_is ;;;sample        sentence.\"))\n",
    "type(preprocess_sentence(\"This @_is ;;;sample        sentence.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earlier-scholar",
   "metadata": {},
   "source": [
    "#### Step 2_1. 방법1 \n",
    " - *preprocess_sentence1*은 split 후에 if - else 를 사용하여 토큰 개수를 세서 14 초과이면 14까지 슬라이싱해서 넣고 14이하이면 그냥 넣는 방법이다. 하지만 이 방법으로 데이터 정제를 한 후에 데이터 수가 너무 많아서 학습하는데 시간이 오래걸리고, 긴 문장은 제외하라는 과제에 적합하지 않아 사용하지 않았다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "electrical-lawsuit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> this is sample sentence .  <end>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_sentence1(sentence):\n",
    "\n",
    "    sentence = sentence.lower().strip()       # 소문자로 바꾸고 양쪽 공백을 삭제\n",
    "  \n",
    "    # 아래 3단계를 거쳐 sentence는 스페이스 1개를 delimeter로 하는 소문자 단어 시퀀스로 바뀝니다.\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)        # 패턴의 특수문자를 만나면 특수문자 양쪽에 공백을 추가\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)                  # 공백 패턴을 만나면 스페이스 1개로 치환\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence)  # a-zA-Z?.!,¿ 패턴을 제외한 모든 문자(공백문자까지도)를 스페이스 1개로 치환\n",
    "    \n",
    "    sentence=re.split(\" \", sentence)\n",
    "    \n",
    "    if len(sentence) > 14 : short_sentence = sentence[:14]\n",
    "        \n",
    "    else : short_sentence = sentence\n",
    "    \n",
    "    short_sentence = \" \".join(short_sentence)\n",
    "    short_sentence = '<start> ' + short_sentence + ' <end>'      # 이전 스텝에서 본 것처럼 문장 앞뒤로 <start>와 <end>를 단어처럼 붙여 줍니다\n",
    "    \n",
    "    return short_sentence\n",
    "\n",
    "print(preprocess_sentence1(\"This @_is ;;;sample        sentence.\"))   # 이 문장이 어떻게 필터링되는지 확인해 보세요.\n",
    "#print(len(preprocess_sentence(\"This @_is ;;;sample        sentence.\"))\n",
    "type(preprocess_sentence1(\"This @_is ;;;sample        sentence.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animal-fireplace",
   "metadata": {},
   "source": [
    "#### Step 2_2. 방법2 \n",
    "- *preprocess_sentence2* 은 문장을 *split* 후에 *if - else* 를 사용하여 토큰 개수를 세서 14 이상이면 *return False* 를 하고 *else* 이면 *.join* 함수를 써서 *split* 한 것을 붙인 다음 문장을 *return* 한다. *return False* 한 값은 아래 코드 *for - if* 문에서 다시 한번 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "increased-country",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> this is sample sentence .  <end>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_sentence2(sentence):\n",
    "\n",
    "    sentence = sentence.lower().strip()       # 소문자로 바꾸고 양쪽 공백을 삭제\n",
    "  \n",
    "    # 아래 3단계를 거쳐 sentence는 스페이스 1개를 delimeter로 하는 소문자 단어 시퀀스로 바뀝니다.\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)        # 패턴의 특수문자를 만나면 특수문자 양쪽에 공백을 추가\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)                  # 공백 패턴을 만나면 스페이스 1개로 치환\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence)  # a-zA-Z?.!,¿ 패턴을 제외한 모든 문자(공백문자까지도)를 스페이스 1개로 치환\n",
    "    \n",
    "    sentence=re.split(\" \", sentence)\n",
    "    \n",
    "    if len(sentence) > 13 : \n",
    "        return False\n",
    "    \n",
    "    else : \n",
    "        sentence = \" \".join(sentence)\n",
    "        sentence = '<start> ' + sentence + ' <end>'      # 이전 스텝에서 본 것처럼 문장 앞뒤로 <start>와 <end>를 단어처럼 붙여 줍니다\n",
    "    \n",
    "        return sentence\n",
    "\n",
    "print(preprocess_sentence2(\"This @_is ;;;sample        sentence.\"))   # 이 문장이 어떻게 필터링되는지 확인해 보세요.\n",
    "#print(len(preprocess_sentence(\"This @_is ;;;sample        sentence.\"))\n",
    "type(preprocess_sentence2(\"This @_is ;;;sample        sentence.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "commercial-wrist",
   "metadata": {},
   "source": [
    "#### Step 2_3. 방법2\n",
    " - *for - if* 문으로 *preprocess_sentence2* 에서 *return* 값이 *False* 이면 *continue* 로 제외시킨다.\n",
    " - tokenize 전에 정제된 데이터 수를 확인한다.\n",
    " - 정제된 데이터 수가 너무 적거나 많으면 다른 방법을 생각한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "preceding-cartridge",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<start> there must be some kind of way outta here <end>', '<start> said the joker to the thief <end>', '<start> there s too much confusion <end>', '<start> i can t get no relief business men , they drink my wine <end>', '<start> plowman dig my earth <end>', '<start> none were level on the mind <end>', '<start> nobody up at his word <end>', '<start> hey , hey no reason to get excited <end>', '<start> the thief he kindly spoke <end>', '<start> there are many here among us <end>']\n",
      "<class 'list'>\n",
      "154531\n"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "\n",
    "for sentence in raw_corpus:\n",
    "    #print(len(sentence))\n",
    "    if len(sentence) == 0: continue\n",
    "    if sentence[-1] == \":\": continue\n",
    "    if preprocess_sentence2(sentence) == False : continue\n",
    "    #print(len(sentence))\n",
    "    corpus.append(preprocess_sentence2(sentence))\n",
    "        \n",
    "print(corpus[:10])\n",
    "print(type(corpus))\n",
    "print(len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-jumping",
   "metadata": {},
   "source": [
    "#### Step 2_4. tokenize \n",
    "- *tokenize* 의 *num_words* 는 *14000* 으로 했다. *tensor*, *tokenizer* 를 출력하여 확인해보니 단어가 숫자화 되고 끝 부분은 0으로 *padding* 된 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "potential-advice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2   61  272 ...    0    0    0]\n",
      " [   2  119    6 ...    0    0    0]\n",
      " [   2   61   17 ...    0    0    0]\n",
      " ...\n",
      " [   2    6  583 ...    0    0    0]\n",
      " [   2    7  214 ...    0    0    0]\n",
      " [   2    8 3374 ...    0    0    0]]\n",
      "<keras_preprocessing.text.Tokenizer object at 0x7fc67692eed0>\n"
     ]
    }
   ],
   "source": [
    "def tokenize(corpus):\n",
    "    # 텐서플로우에서 제공하는 Tokenizer 패키지를 생성\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        num_words=14000,  # 전체 단어의 개수 \n",
    "        filters=' ',    # 별도로 전처리 로직을 추가할 수 있습니다. 이번에는 사용하지 않겠습니다.\n",
    "        oov_token=\"<unk>\"  # out-of-vocabulary, 사전에 없었던 단어는 어떤 토큰으로 대체할지\n",
    "    )\n",
    "    tokenizer.fit_on_texts(corpus)   # 우리가 구축한 corpus로부터 Tokenizer가 사전을 자동구축하게 됩니다.\n",
    "\n",
    "    # 이후 tokenizer를 활용하여 모델에 입력할 데이터셋을 구축하게 됩니다.\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)   # tokenizer는 구축한 사전으로부터 corpus를 해석해 Tensor로 변환합니다.\n",
    "\n",
    "    # 입력 데이터의 시퀀스 길이를 일정하게 맞추기 위한 padding  메소드를 제공합니다.\n",
    "    # maxlen의 디폴트값은 None입니다. 이 경우 corpus의 가장 긴 문장을 기준으로 시퀀스 길이가 맞춰집니다.\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')  \n",
    "\n",
    "    print(tensor,sep='\\n')\n",
    "    print(tokenizer)\n",
    "    return tensor, tokenizer\n",
    "\n",
    "tensor, tokenizer = tokenize(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-teach",
   "metadata": {},
   "source": [
    "#### Step 2_5. tokenize 값 확인 \n",
    "- 텐서화 된 값을 자세히 출력해보면 이와같이 앞부분엔 무조건  *start* 가 있어 2 인 것을 확인할 수 있다. 그리고 문장 끝엔 3으로  *end* 가 들어간 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "immune-pressure",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2   61  272   27   94  551   20   86  750   90]\n",
      " [   2  119    6 6225   10    6 2289    3    0    0]\n",
      " [   2   61   17  102  187 2688    3    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "print(tensor[:3, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "recorded-matrix",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : <unk>\n",
      "2 : <start>\n",
      "3 : <end>\n",
      "4 : i\n",
      "5 : ,\n",
      "6 : the\n",
      "7 : you\n",
      "8 : and\n",
      "9 : a\n",
      "10 : to\n"
     ]
    }
   ],
   "source": [
    "for idx in tokenizer.index_word:\n",
    "    print(idx, \":\", tokenizer.index_word[idx])\n",
    "\n",
    "    if idx >= 10: break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleared-biodiversity",
   "metadata": {},
   "source": [
    "##### 총 데이터셋 행렬 모양은 (154531, 14) 이고 src_input 과 tgt_input 모양이 같다는 것을 확인했다. \n",
    "- 문장 수 : 154531\n",
    "- 문장의 최대 단어(토큰) 개수 : 14개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "coral-dispute",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2  61 272  27  94 551  20  86 750  90   3   0   0   0]\n",
      "[ 61 272  27  94 551  20  86 750  90   3   0   0   0   0]\n",
      "154531\n",
      "154531\n",
      "<class 'numpy.ndarray'>\n",
      "(154531, 14)\n"
     ]
    }
   ],
   "source": [
    "src_input = tensor[:, :-1]  # tensor에서 마지막 토큰을 잘라내서 소스 문장을 생성합니다. 마지막 토큰은 <end>가 아니라 <pad>일 가능성이 높습니다.\n",
    "tgt_input = tensor[:, 1:]    # tensor에서 <start>를 잘라내서 타겟 문장을 생성합니다.\n",
    "\n",
    "print(src_input[0])\n",
    "print(tgt_input[0])\n",
    "print(len(src_input))\n",
    "print(len(tgt_input))\n",
    "print(type(src_input))\n",
    "print(src_input.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closed-submission",
   "metadata": {},
   "source": [
    "### Step 3. 평가 데이터셋 분리\n",
    "- tokenize() 함수로 데이터를 Tensor로 변환한 후, sklearn 모듈의 train_test_split() 함수를 사용해 훈련 데이터와 평가 데이터를 분리했다.단어장의 크기는 14,000이고 총 데이터의 20%를 평가 데이터셋으로 사용했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "north-capacity",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "enc_train, enc_val = train_test_split(src_input, \n",
    "                                        test_size=0.2,\n",
    "                                        random_state=34,\n",
    "                                        shuffle=True)\n",
    "dec_train, dec_val = train_test_split(tgt_input, \n",
    "                                        test_size=0.2,\n",
    "                                        random_state=34,\n",
    "                                        shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-maple",
   "metadata": {},
   "source": [
    "### Step 3-1. 평가 데이터셋 갯수 확인\n",
    "- 데이터셋을 분리했을 때, 학습 데이터 갯수가 과제 목표 124960보다 작은 것을 확인했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "grateful-pollution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Train: (123624, 14)\n",
      "Target Train: (123624, 14)\n"
     ]
    }
   ],
   "source": [
    "print(\"Source Train:\", enc_train.shape)\n",
    "print(\"Target Train:\", dec_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "terminal-horizon",
   "metadata": {},
   "source": [
    "### Step 3-2. BUFFER_SIZE, dataset, val_dataset 설정 \n",
    "- *BUFFER_SIZE* , *dataset* , *val_dataset* 에 split한 값들을 넣어주었다. *dataset* 에 *src_input*, *tgt_input* 값을 넣어 학습도 해보았는데, *val_loss* 값이 2.1로 낮게 나왔다. 이는 *src_input*, *tgt_input* dataset 안에 *enc_val*, *dec_val* 데이터가 포함되어 있어 *val_loss* 가 낮게 나온 것 같다. 하지만 dataset 안에 *src_input*, *tgt_input* 을 넣으면 sklearn 모듈의 train_test_split() 함수를 이용해 *enc_train,dec_train* 값을 얻은 의미가 없으므로 loss를 줄이기 위해 src_input, tgt_input 값을 dataset에 넣기보단 *enc_train* , *dec_train* 값을 넣어야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abandoned-medicare",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123624\n",
      "482\n"
     ]
    }
   ],
   "source": [
    "BUFFER_SIZE = len(enc_train)\n",
    "print(len(enc_train))\n",
    "BATCH_SIZE = 256\n",
    "steps_per_epoch = len(enc_train) // BATCH_SIZE\n",
    "print(steps_per_epoch)\n",
    "VOCAB_SIZE = tokenizer.num_words + 1    # tokenizer가 구축한 단어사전 내 7000개와, 여기 포함되지 않은 0:<pad>를 포함하여 7001개\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((enc_val, dec_val)).shuffle(len(enc_val))\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subject-differential",
   "metadata": {},
   "source": [
    "### Step 4. 인공지능 만들기\n",
    "- RNN을 사용했다. hidden_size를 2048로 높게 주었다. 임베딩을 통해 단어들간의 상대적인 거리 값으로 학습한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "laden-marriage",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super(TextGenerator, self).__init__()\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "embedding_size = 256\n",
    "hidden_size = 2048\n",
    "model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)\\\n",
    "#print(\"f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-buffalo",
   "metadata": {},
   "source": [
    "### Step 4_1. 셈플확인\n",
    "- 최종 출력 텐서 shape가 shape=(256, 14, 14001)인 것을 확인 했다. 14001은 Dense 레이어의 출력 차원 수 이다. 14001개의 단어 중 어느 단어의 확률이 가장 높을지를 모델링해야 하기 때문이다. 256은 배치 사이즈이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "norwegian-madison",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 14, 14001), dtype=float32, numpy=\n",
       "array([[[ 7.3888616e-05,  4.1382926e-04, -1.3355503e-04, ...,\n",
       "          2.4013220e-04, -1.6636026e-04,  3.5196939e-05],\n",
       "        [ 1.8130390e-04,  6.0105446e-04, -2.2397129e-04, ...,\n",
       "         -3.2661126e-05, -4.3243633e-04,  1.4015993e-04],\n",
       "        [ 3.1436139e-04,  8.2724454e-04,  4.0651063e-05, ...,\n",
       "         -2.1022202e-04, -6.4477813e-04,  1.5606832e-04],\n",
       "        ...,\n",
       "        [ 3.4853735e-04,  4.1987450e-04, -1.2359800e-04, ...,\n",
       "         -2.5477511e-04,  8.6093909e-04, -4.1772844e-04],\n",
       "        [ 3.9464838e-04,  7.7889890e-05, -2.5878238e-04, ...,\n",
       "          1.6956119e-04,  9.0672815e-04, -4.5339690e-04],\n",
       "        [ 4.8283782e-04, -2.8222139e-04, -3.6002140e-04, ...,\n",
       "          6.0202961e-04,  8.8616187e-04, -5.1320856e-04]],\n",
       "\n",
       "       [[ 7.3888616e-05,  4.1382926e-04, -1.3355503e-04, ...,\n",
       "          2.4013220e-04, -1.6636026e-04,  3.5196939e-05],\n",
       "        [-1.2775954e-04,  4.6104289e-04,  5.2953732e-05, ...,\n",
       "          7.0682674e-04,  1.4231347e-04,  8.6757515e-05],\n",
       "        [-3.6743257e-04,  1.5501164e-04,  2.3223563e-04, ...,\n",
       "          9.9478138e-04,  4.6682841e-04,  2.2551623e-04],\n",
       "        ...,\n",
       "        [-9.0246840e-06, -1.9317308e-04, -2.5868710e-04, ...,\n",
       "          8.7687782e-05,  4.8857584e-04,  6.0618389e-04],\n",
       "        [ 1.2282447e-04, -4.2358611e-04, -2.9387564e-04, ...,\n",
       "          3.9482181e-04,  4.0950617e-04,  4.8197788e-04],\n",
       "        [ 2.6933991e-04, -7.1526680e-04, -2.9145723e-04, ...,\n",
       "          7.0704881e-04,  2.7284917e-04,  3.5683467e-04]],\n",
       "\n",
       "       [[ 7.3888616e-05,  4.1382926e-04, -1.3355503e-04, ...,\n",
       "          2.4013220e-04, -1.6636026e-04,  3.5196939e-05],\n",
       "        [-6.2091072e-05,  4.5394819e-04, -1.1892567e-04, ...,\n",
       "          1.4104779e-04, -2.5561592e-04, -1.7880683e-04],\n",
       "        [-8.7421373e-05,  2.8161757e-04,  1.9933202e-04, ...,\n",
       "          1.9808160e-04, -1.8365891e-04, -2.9349959e-04],\n",
       "        ...,\n",
       "        [-4.2701366e-05, -8.6188910e-04, -1.0433142e-03, ...,\n",
       "          1.5645092e-03, -1.2600240e-04, -4.1870901e-04],\n",
       "        [ 1.8115275e-04, -1.1178133e-03, -8.9940231e-04, ...,\n",
       "          1.7663026e-03, -2.7359553e-04, -4.1064023e-04],\n",
       "        [ 3.6815833e-04, -1.3826637e-03, -7.2613446e-04, ...,\n",
       "          1.9508444e-03, -4.5703386e-04, -3.8655187e-04]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 7.3888616e-05,  4.1382926e-04, -1.3355503e-04, ...,\n",
       "          2.4013220e-04, -1.6636026e-04,  3.5196939e-05],\n",
       "        [ 1.8130390e-04,  6.0105446e-04, -2.2397129e-04, ...,\n",
       "         -3.2661126e-05, -4.3243633e-04,  1.4015993e-04],\n",
       "        [ 2.4012812e-04,  4.1533238e-04, -2.5336351e-04, ...,\n",
       "         -1.2239718e-04, -4.0336850e-04,  3.4885763e-04],\n",
       "        ...,\n",
       "        [ 6.3441013e-04, -1.0603374e-03,  4.6219782e-04, ...,\n",
       "          7.5813371e-04,  5.4716278e-04,  8.2879199e-04],\n",
       "        [ 7.9320429e-04, -1.3429712e-03,  4.9816637e-04, ...,\n",
       "          1.1043915e-03,  3.0608935e-04,  6.8413134e-04],\n",
       "        [ 9.0093911e-04, -1.6095814e-03,  5.3495314e-04, ...,\n",
       "          1.4162624e-03,  2.9700699e-05,  5.6597171e-04]],\n",
       "\n",
       "       [[ 7.3888616e-05,  4.1382926e-04, -1.3355503e-04, ...,\n",
       "          2.4013220e-04, -1.6636026e-04,  3.5196939e-05],\n",
       "        [ 2.9020250e-04,  8.2259672e-04, -1.1489040e-04, ...,\n",
       "          3.8035336e-04, -5.8259971e-05,  1.8948502e-05],\n",
       "        [ 4.2903589e-04,  1.1670634e-03, -9.0622103e-05, ...,\n",
       "          5.4269680e-04,  7.1514092e-05,  1.5466596e-04],\n",
       "        ...,\n",
       "        [-8.0048532e-04,  9.6310431e-04, -1.2779339e-04, ...,\n",
       "          1.5600156e-03, -3.4988683e-04,  2.1053539e-04],\n",
       "        [-7.1435160e-04,  8.2169950e-04, -1.2054307e-04, ...,\n",
       "          1.6974958e-03, -3.9406694e-04,  1.1879460e-04],\n",
       "        [-5.1701919e-04,  5.2864751e-04, -1.2909209e-04, ...,\n",
       "          1.8767455e-03, -4.2963238e-04,  1.5077914e-05]],\n",
       "\n",
       "       [[ 7.3888616e-05,  4.1382926e-04, -1.3355503e-04, ...,\n",
       "          2.4013220e-04, -1.6636026e-04,  3.5196939e-05],\n",
       "        [ 1.8130390e-04,  6.0105446e-04, -2.2397129e-04, ...,\n",
       "         -3.2661126e-05, -4.3243633e-04,  1.4015993e-04],\n",
       "        [ 5.9874216e-04,  4.9790350e-04, -3.2777651e-04, ...,\n",
       "         -2.8389230e-04, -5.9906073e-04,  2.9725398e-04],\n",
       "        ...,\n",
       "        [ 9.9340721e-04, -1.9156067e-03, -5.3988799e-04, ...,\n",
       "          1.8560750e-03,  6.5104687e-05, -4.1244991e-04],\n",
       "        [ 1.0872982e-03, -2.1593820e-03, -3.7893228e-04, ...,\n",
       "          2.0937626e-03, -8.4136045e-05, -4.4820382e-04],\n",
       "        [ 1.1397875e-03, -2.3664918e-03, -2.1492933e-04, ...,\n",
       "          2.2864440e-03, -2.8182138e-04, -4.4651513e-04]]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for src_sample, tgt_sample in dataset.take(1): break\n",
    "model(src_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "another-sphere",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  3584256   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  multiple                  18882560  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                multiple                  33562624  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  28688049  \n",
      "=================================================================\n",
      "Total params: 84,717,489\n",
      "Trainable params: 84,717,489\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absent-jesus",
   "metadata": {},
   "source": [
    "### Step 4_2. model.fit\n",
    "- 만들어둔 dataset과 val_dataset 변수를 넣어주고 epoch을 10으로 하여 fit 해주었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "contrary-thread",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "482/482 [==============================] - 214s 445ms/step - loss: 3.4614 - val_loss: 3.0340\n",
      "Epoch 2/10\n",
      "482/482 [==============================] - 216s 449ms/step - loss: 2.8494 - val_loss: 2.7582\n",
      "Epoch 3/10\n",
      "482/482 [==============================] - 216s 449ms/step - loss: 2.5453 - val_loss: 2.5826\n",
      "Epoch 4/10\n",
      "482/482 [==============================] - 216s 448ms/step - loss: 2.2619 - val_loss: 2.4511\n",
      "Epoch 5/10\n",
      "482/482 [==============================] - 216s 449ms/step - loss: 1.9966 - val_loss: 2.3524\n",
      "Epoch 6/10\n",
      "482/482 [==============================] - 216s 449ms/step - loss: 1.7533 - val_loss: 2.2795\n",
      "Epoch 7/10\n",
      "482/482 [==============================] - 211s 438ms/step - loss: 1.5392 - val_loss: 2.2299\n",
      "Epoch 8/10\n",
      "482/482 [==============================] - 211s 437ms/step - loss: 1.3593 - val_loss: 2.2049\n",
      "Epoch 9/10\n",
      "482/482 [==============================] - 215s 447ms/step - loss: 1.2165 - val_loss: 2.1962\n",
      "Epoch 10/10\n",
      "482/482 [==============================] - 216s 447ms/step - loss: 1.1121 - val_loss: 2.2056\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f969a96c190>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True,\n",
    "    reduction='none'\n",
    ")\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer)\n",
    "#model.fit(dataset, epochs=10, validation_data = val_dataset ,steps_per_epoch = steps_per_epoch, validation_steps=len(dec_val) // BATCH_SIZE )\n",
    "model.fit(dataset, epochs=10, validation_data = val_dataset , verbose=1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-morrison",
   "metadata": {},
   "source": [
    "### Step 4_3. model_2.fit\n",
    "- *embedding_size* 는 128, *hidden_size* 는 512로 낮췄고 *model.fit* 에 *steps_per_epoch* 과 *validation_steps* 를 추가했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "suspended-retailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf    \n",
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super(TextGenerator, self).__init__()\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "divided-frequency",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size_2 = 128\n",
    "hidden_size_2 = 512\n",
    "model_2 = TextGenerator(tokenizer.num_words + 1, embedding_size_2 , hidden_size_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "partial-timeline",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 4.61983618e-05  1.28776825e-04 -1.28940710e-05 ... -2.61390123e-05\n",
      "   -5.62482710e-05 -9.45804786e-05]\n",
      "  [ 8.93667748e-05  3.35953315e-04 -1.24634404e-04 ... -9.08685543e-05\n",
      "   -2.43263581e-04 -8.70585573e-05]\n",
      "  [ 1.18553915e-04  4.59706731e-04 -2.24252537e-04 ... -5.23334056e-05\n",
      "   -3.13927128e-04 -1.40209973e-04]\n",
      "  ...\n",
      "  [ 7.45711615e-04 -1.77426686e-04  6.06938789e-04 ...  7.84657139e-04\n",
      "   -7.74085784e-05 -5.39239729e-04]\n",
      "  [ 7.21409451e-04 -5.11271646e-04  7.26565020e-04 ...  9.84451151e-04\n",
      "    8.28722768e-05 -4.62498429e-04]\n",
      "  [ 6.91659981e-04 -8.37180007e-04  8.50728073e-04 ...  1.23667158e-03\n",
      "    2.09569451e-04 -3.50118469e-04]]\n",
      "\n",
      " [[ 4.61983618e-05  1.28776825e-04 -1.28940710e-05 ... -2.61390123e-05\n",
      "   -5.62482710e-05 -9.45804786e-05]\n",
      "  [ 6.58722493e-05  2.35572428e-04  6.71554371e-05 ... -2.11743347e-04\n",
      "   -1.44181875e-04 -3.10965755e-04]\n",
      "  [-1.72630011e-04  1.54362599e-04  8.06819880e-05 ... -2.72627076e-04\n",
      "   -1.96040317e-04 -4.19298740e-04]\n",
      "  ...\n",
      "  [ 1.30239897e-03 -3.03611414e-05  3.85360443e-04 ...  3.85826803e-04\n",
      "    4.71761770e-04 -4.43287776e-04]\n",
      "  [ 1.21242122e-03 -3.44815460e-04  5.90497802e-04 ...  7.95695407e-04\n",
      "    5.65844646e-04 -3.25675675e-04]\n",
      "  [ 1.12055510e-03 -6.63612445e-04  7.94427237e-04 ...  1.22038764e-03\n",
      "    6.16810401e-04 -1.96142180e-04]]\n",
      "\n",
      " [[ 4.61983618e-05  1.28776825e-04 -1.28940710e-05 ... -2.61390123e-05\n",
      "   -5.62482710e-05 -9.45804786e-05]\n",
      "  [ 1.49583575e-04  1.01922487e-04  4.73665532e-05 ... -7.96827808e-05\n",
      "   -3.90286878e-05 -2.32883307e-04]\n",
      "  [ 2.20962043e-04 -2.01352872e-04  2.42700899e-05 ... -1.15129682e-04\n",
      "   -1.48465508e-04 -2.96843325e-04]\n",
      "  ...\n",
      "  [-3.77377553e-04 -6.87180029e-04  8.36749605e-05 ... -3.68837354e-04\n",
      "    8.85118352e-05  1.74280693e-04]\n",
      "  [-3.21991625e-04 -8.59046646e-04  1.75012246e-04 ... -1.72947577e-04\n",
      "    3.09839728e-04  2.35625441e-04]\n",
      "  [-2.68200907e-04 -1.06694142e-03  2.85641290e-04 ...  1.08019711e-04\n",
      "    4.99450834e-04  3.00924410e-04]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 4.61983618e-05  1.28776825e-04 -1.28940710e-05 ... -2.61390123e-05\n",
      "   -5.62482710e-05 -9.45804786e-05]\n",
      "  [-1.02446400e-04  1.79828392e-04 -1.60300206e-05 ... -1.04737417e-04\n",
      "   -1.22474972e-04 -1.81045296e-04]\n",
      "  [-3.93549853e-04  1.23073740e-04 -3.30055154e-05 ... -2.66609888e-04\n",
      "   -1.55293135e-04 -3.94859613e-04]\n",
      "  ...\n",
      "  [-5.09473139e-05 -1.36723393e-03  4.90984879e-04 ...  7.25502730e-04\n",
      "    5.57725900e-04 -3.88223183e-04]\n",
      "  [ 1.60321779e-05 -1.59937551e-03  6.79087127e-04 ...  1.15044462e-03\n",
      "    6.07879192e-04 -2.41790956e-04]\n",
      "  [ 8.57769264e-05 -1.81449822e-03  8.66393617e-04 ...  1.56955107e-03\n",
      "    6.12303498e-04 -1.02076447e-04]]\n",
      "\n",
      " [[ 4.61983618e-05  1.28776825e-04 -1.28940710e-05 ... -2.61390123e-05\n",
      "   -5.62482710e-05 -9.45804786e-05]\n",
      "  [ 7.25692880e-05  7.39529278e-05  1.58268449e-04 ... -1.24088532e-04\n",
      "   -8.32377846e-05 -2.59406486e-04]\n",
      "  [ 2.17334571e-04 -4.15134964e-05  2.17148394e-04 ... -1.59065530e-04\n",
      "   -1.24493090e-04 -3.02404282e-04]\n",
      "  ...\n",
      "  [ 3.17086990e-04 -4.27442224e-04  4.76822897e-04 ...  5.79856161e-04\n",
      "    4.08865220e-04  4.34847934e-05]\n",
      "  [ 3.30309209e-04 -7.27238017e-04  6.25795336e-04 ...  8.88774928e-04\n",
      "    5.02085139e-04  1.02623315e-04]\n",
      "  [ 3.43965425e-04 -1.02803088e-03  7.82583898e-04 ...  1.23227993e-03\n",
      "    5.55262959e-04  1.67753315e-04]]\n",
      "\n",
      " [[ 4.61983618e-05  1.28776825e-04 -1.28940710e-05 ... -2.61390123e-05\n",
      "   -5.62482710e-05 -9.45804786e-05]\n",
      "  [ 1.59215677e-04  2.92220822e-04 -4.08152391e-06 ...  1.33259236e-04\n",
      "   -1.53289202e-05 -6.40172875e-05]\n",
      "  [-8.34555758e-05  4.02835954e-04  2.64184782e-04 ...  2.30115940e-04\n",
      "    3.53009673e-05 -1.37764699e-04]\n",
      "  ...\n",
      "  [-4.85632365e-04 -5.35295752e-04  2.26817996e-04 ...  4.04399791e-04\n",
      "    3.32854281e-04 -1.56185182e-04]\n",
      "  [-2.72045610e-04 -7.82192976e-04  2.38519104e-04 ...  6.15698867e-04\n",
      "    4.90248436e-04 -2.16505854e-04]\n",
      "  [-9.81058547e-05 -1.04762043e-03  2.89922813e-04 ...  8.83807428e-04\n",
      "    6.20833249e-04 -2.17696026e-04]]], shape=(256, 14, 14001), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for src_sample, tgt_sample in dataset.take(1): break\n",
    "print(model_2(src_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "amazing-slope",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      multiple                  1792128   \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                multiple                  1312768   \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                multiple                  2099200   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  7182513   \n",
      "=================================================================\n",
      "Total params: 12,386,609\n",
      "Trainable params: 12,386,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "circular-distance",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True,\n",
    "    reduction='none'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "entertaining-scholarship",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(loss=loss, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "satellite-shoot",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps_per_epoch :  482\n",
      "validation_steps :  120\n"
     ]
    }
   ],
   "source": [
    "print(\"steps_per_epoch : \", steps_per_epoch)\n",
    "print(\"validation_steps : \", len(dec_val) // BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "silver-surgeon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "482/482 [==============================] - 32s 66ms/step - loss: 3.8137 - val_loss: 3.3069\n",
      "Epoch 2/10\n",
      "482/482 [==============================] - 32s 67ms/step - loss: 3.1844 - val_loss: 3.1096\n",
      "Epoch 3/10\n",
      "482/482 [==============================] - 32s 67ms/step - loss: 3.0346 - val_loss: 3.0084\n",
      "Epoch 4/10\n",
      "482/482 [==============================] - 32s 67ms/step - loss: 2.9350 - val_loss: 2.9373\n",
      "Epoch 5/10\n",
      "482/482 [==============================] - 32s 67ms/step - loss: 2.8512 - val_loss: 2.8766\n",
      "Epoch 6/10\n",
      "482/482 [==============================] - 32s 67ms/step - loss: 2.7769 - val_loss: 2.8232\n",
      "Epoch 7/10\n",
      "482/482 [==============================] - 32s 67ms/step - loss: 2.7082 - val_loss: 2.7794\n",
      "Epoch 8/10\n",
      "482/482 [==============================] - 33s 67ms/step - loss: 2.6442 - val_loss: 2.7414\n",
      "Epoch 9/10\n",
      "482/482 [==============================] - 32s 67ms/step - loss: 2.5830 - val_loss: 2.7087\n",
      "Epoch 10/10\n",
      "482/482 [==============================] - 33s 67ms/step - loss: 2.5251 - val_loss: 2.6791\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc6685e2d50>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit(dataset, epochs=10, validation_data = val_dataset ,steps_per_epoch = steps_per_epoch, validation_steps=len(dec_val) // BATCH_SIZE )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "august-shepherd",
   "metadata": {},
   "source": [
    "### Step 5. 인공지능 Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "matched-meditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
    "    # 테스트를 위해서 입력받은 init_sentence도 일단 텐서로 변환합니다.\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "    # 텍스트를 실제로 생성할때는 루프를 돌면서 단어 하나씩 생성해야 합니다. \n",
    "    while True:\n",
    "        predict = model(test_tensor)  # 입력받은 문장의 텐서를 입력합니다. \n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1]   # 우리 모델이 예측한 마지막 단어가 바로 새롭게 생성한 단어가 됩니다. \n",
    "\n",
    "        # 우리 모델이 새롭게 예측한 단어를 입력 문장의 뒤에 붙여 줍니다. \n",
    "        test_tensor = tf.concat([test_tensor, \n",
    "                                                                 tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "\n",
    "        # 우리 모델이 <end>를 예측했거나, max_len에 도달하지 않았다면  while 루프를 또 돌면서 다음 단어를 예측해야 합니다.\n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "    generated = \"\"\n",
    "    # 생성된 tensor 안에 있는 word index를 tokenizer.index_word 사전을 통해 실제 단어로 하나씩 변환합니다. \n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "    return generated   # 이것이 최종적으로 모델이 생성한 자연어 문장입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-oklahoma",
   "metadata": {},
   "source": [
    "### Step 5_1. hidden size = 2048 일 때 가사 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "owned-brazilian",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i love ma little nasty girl <end> '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> i love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "allied-westminster",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> turn up the bass til it s up in your face level <end> '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> turn up\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "processed-tragedy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> flex in the morning <end> '"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> flex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "downtown-interest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i make it spin on my finger im a critical thinker <end> '"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> I make it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "violent-ultimate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> im rockin the flow i pop em the other day <end> '"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> im rockin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "metallic-steam",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> so easy to say <end> '"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> so easy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "marine-twist",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> god damn , god damn <end> '"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> god\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sitting-affect",
   "metadata": {},
   "source": [
    "### Step 5_2. hidden size = 512, embedding_size = 128 일 때 가사 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "norman-robinson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i love you , i m a <unk> <end> '"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model_2, tokenizer, init_sentence=\"<start> i love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "municipal-picnic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> turn up on the floor <end> '"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model_2, tokenizer, init_sentence=\"<start> turn up\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "convenient-conspiracy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> flex alert , major bag alert major <end> '"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model_2, tokenizer, init_sentence=\"<start> flex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "technological-territory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i make it factual <end> '"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model_2, tokenizer, init_sentence=\"<start> I make it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "thousand-buddy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> im rockin on the wall <end> '"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model_2, tokenizer, init_sentence=\"<start> im rockin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "included-therapy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> so easy , i m so glad <end> '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model_2, tokenizer, init_sentence=\"<start> so easy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "typical-lightweight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> god s the only one <end> '"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model_2, tokenizer, init_sentence=\"<start> god\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-worse",
   "metadata": {},
   "source": [
    "# 마치며 ...\n",
    " - 처음에 maxlen을 안쓰고 토큰화 하는 방법을 고민하다가 split, join, if-else-continue 방법으로 잘 되어 기뻤다. 하지만 val_loss가 잘 나와도 2.4정도까지 밖에 안내려가서 epochs도 낮춰보고, steps_per_epoch, validation_steps 값도 넣어보고, embedding_size, hidden_size 값을 낮추어 봤는데 계속 2.4 이상이 나왔다. 그래서 hidden_size 값을 2048로 대폭 올렸더니 val_loss가 2.2 이하가 나와서 기뻤다. 하지만 hidden_size 값을 2048로 주면 학습시간이 엄청 늘어났다. hidden_size = 1024 학습시간은 20분 정도 걸렸던거 같은데 hidden_size = 2048 학습시간은 1시간 정도 걸린 것 같다.   \n",
    "---\n",
    "- 노래 가사 출력은 hidden_size = 2048일 때 오버피팅 되지 않고 적절하게 출력된 것 같다. 힙합을 좋아해서 힙합에서 나오는 가사들을 몇개 넣어봤는데 만족스럽다. val_loss가 2.68(hidden_size = 512) 인 모델과 2.2(hidden_size = 2048) 인 모델의 출력 가사는 생각보다 달랐다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inappropriate-elevation",
   "metadata": {},
   "source": [
    "평가 문항\t상세 기준\n",
    "1 . 가사 텍스트 생성 모델이 동작 하는가?\n",
    "\n",
    "텍스트 제너레이션 결과가 그럴듯한 문장으로 생성 되는가?\n",
    "2 . 데이터의 전처리와 데이터 셋 구성 과정이 체계적으로 진행 되었습니까?\n",
    "\n",
    "특수 문자 제거, 토크 나이저 생성, 패딩 처리 등의 과정이 빠짐없이 진행 되었습니까?\n",
    "3 . 텍스트 생성 모델이 안정적으로 학습 되었습니까?\n",
    "\n",
    "텍스트 생성 모델의 유효성 검사 손실 2.2 이하로 생성 는가?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
