{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "842d7260",
   "metadata": {},
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac0dd7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"joints_vis\": [\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"joints\": [\n",
      "    [\n",
      "      620.0,\n",
      "      394.0\n",
      "    ],\n",
      "    [\n",
      "      616.0,\n",
      "      269.0\n",
      "    ],\n",
      "    [\n",
      "      573.0,\n",
      "      185.0\n",
      "    ],\n",
      "    [\n",
      "      647.0,\n",
      "      188.0\n",
      "    ],\n",
      "    [\n",
      "      661.0,\n",
      "      221.0\n",
      "    ],\n",
      "    [\n",
      "      656.0,\n",
      "      231.0\n",
      "    ],\n",
      "    [\n",
      "      610.0,\n",
      "      187.0\n",
      "    ],\n",
      "    [\n",
      "      647.0,\n",
      "      176.0\n",
      "    ],\n",
      "    [\n",
      "      637.0201,\n",
      "      189.8183\n",
      "    ],\n",
      "    [\n",
      "      695.9799,\n",
      "      108.1817\n",
      "    ],\n",
      "    [\n",
      "      606.0,\n",
      "      217.0\n",
      "    ],\n",
      "    [\n",
      "      553.0,\n",
      "      161.0\n",
      "    ],\n",
      "    [\n",
      "      601.0,\n",
      "      167.0\n",
      "    ],\n",
      "    [\n",
      "      692.0,\n",
      "      185.0\n",
      "    ],\n",
      "    [\n",
      "      693.0,\n",
      "      240.0\n",
      "    ],\n",
      "    [\n",
      "      688.0,\n",
      "      313.0\n",
      "    ]\n",
      "  ],\n",
      "  \"image\": \"015601864.jpg\",\n",
      "  \"scale\": 3.021046,\n",
      "  \"center\": [\n",
      "    594.0,\n",
      "    257.0\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json, os\n",
    "\n",
    "json_file_path = os.getenv('HOME')+'/aiffel/mpii/mpii_human_pose_v1_u12_2/train.json'\n",
    "\n",
    "with open(json_file_path) as train_json:\n",
    "    train_annos = json.load(train_json)\n",
    "    json_formatted_str = json.dumps(train_annos[0], indent=2) # json beautify\n",
    "    print(json_formatted_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c391bcd",
   "metadata": {},
   "source": [
    "## joints 순서\n",
    "\n",
    "0 - 오른쪽 발목  \n",
    "1 - 오른쪽 무릎  \n",
    "2 - 오른쪽 엉덩이  \n",
    "3 - 왼쪽 엉덩이  \n",
    "4 - 왼쪽 무릎  \n",
    "5 - 왼쪽 발목  \n",
    "6 - 골반  \n",
    "7 - 가슴(흉부)  \n",
    "8 - 목  \n",
    "9 - 머리 위  \n",
    "10 - 오른쪽 손목  \n",
    "11 - 오른쪽 팔꿈치  \n",
    "12 - 오른쪽 어깨  \n",
    "13 - 왼쪽 어깨  \n",
    "14 - 왼쪽 팔꿈치  \n",
    "15 - 왼쪽 손목  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0938d9cf",
   "metadata": {},
   "source": [
    "## scale 과 center\n",
    "\n",
    "높이 = scale * 200px\n",
    "center 는 사람의 중심점"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f62fd43",
   "metadata": {},
   "source": [
    "## json annotation 을 파싱하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "520df2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_one_annotation(anno, image_dir):\n",
    "    filename = anno['image']\n",
    "    joints = anno['joints']\n",
    "    joints_visibility = anno['joints_vis']\n",
    "    annotation = {\n",
    "        'filename': filename,\n",
    "        'filepath': os.path.join(image_dir, filename),\n",
    "        'joints_visibility': joints_visibility,\n",
    "        'joints': joints,\n",
    "        'center': anno['center'],\n",
    "        'scale' : anno['scale']\n",
    "    }\n",
    "    return annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d28925e",
   "metadata": {},
   "source": [
    "## tfrecord 파일 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59fb4220",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel-dj17/anaconda3/envs/aiffel/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "  \"update your install command.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "def build_tf_records(annotations, total_shards, split):\n",
    "    chunks = chunkify(annotations, total_shards)\n",
    "    futures = [\n",
    "        # train_0001_of_0064.tfrecords\n",
    "        build_single_tfrecord.remote(\n",
    "            chunk, './tfrecords_mpii/{}_{}_of_{}.tfrecords'.format(\n",
    "                split,\n",
    "                str(i + 1).zfill(4),\n",
    "                str(total_shards).zfill(4),\n",
    "            )) for i, chunk in enumerate(chunks)\n",
    "    ]\n",
    "    ray.get(futures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d474018f",
   "metadata": {},
   "source": [
    "- annotation 을 total_shards 개수로 나눔(chunkify) (train : 64개, val : 8개)\n",
    "- build_single_tfrecord 함수를 통해 tfrecord 로 저장\n",
    "- 각 chunk 끼리 dependency 가 없기 때문에 병렬처리가 가능, ray를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53eef182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunkify(l, n):\n",
    "    size = len(l) // n\n",
    "    start = 0\n",
    "    results = []\n",
    "    for i in range(n - 1):\n",
    "        results.append(l[start:start + size])\n",
    "        start += size\n",
    "    results.append(l[start:])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ef14ae",
   "metadata": {},
   "source": [
    "- l 은 annotation, n은 shard 개수\n",
    "- shard 개수 단위로 annotation list 를 나누어서 새로운 list를 만듦.\n",
    "- numpy array 라고 가정하면 (size, shard, anno_content) 정도의 shape을 가짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9901918a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def build_single_tfrecord(chunk, path):\n",
    "    print('start to build tf records for ' + path)\n",
    "\n",
    "    with tf.io.TFRecordWriter(path) as writer:\n",
    "        for anno_list in chunk:\n",
    "            tf_example = genreate_tfexample(anno_list)\n",
    "            writer.write(tf_example.SerializeToString())\n",
    "\n",
    "    print('finished building tf records for ' + path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8257cba9",
   "metadata": {},
   "source": [
    "## tf.example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "660cda1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tfexample(anno):\n",
    "    filename = anno['filename']\n",
    "    filepath = anno['filepath']\n",
    "    with open(filepath, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = Image.open(filepath)\n",
    "    if image.format != 'JPEG' or image.mode != 'RGB':\n",
    "        image_rgb = image.convert('RGB')\n",
    "        with io.BytesIO() as output:\n",
    "            image_rgb.save(output, format=\"JPEG\", quality=95)\n",
    "            content = output.getvalue()\n",
    "\n",
    "    width, height = image.size\n",
    "    depth = 3\n",
    "\n",
    "    c_x = int(anno['center'][0])\n",
    "    c_y = int(anno['center'][1])\n",
    "    scale = anno['scale']\n",
    "\n",
    "    x = [\n",
    "        int(joint[0]) if joint[0] >= 0 else int(joint[0]) \n",
    "        for joint in anno['joints']\n",
    "    ]\n",
    "    y = [\n",
    "        int(joint[1]) if joint[1] >= 0 else int(joint[0]) \n",
    "        for joint in anno['joints']\n",
    "    ]\n",
    "    # 0 - invisible, 1 - occluded, 2 - visible\n",
    "    v = [0 if joint_v == 0 else 2 for joint_v in anno['joints_visibility']]\n",
    "\n",
    "    feature = {\n",
    "        'image/height':\n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=[height])),\n",
    "        'image/width':\n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=[width])),\n",
    "        'image/depth':\n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=[depth])),\n",
    "        'image/object/parts/x':\n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=x)),\n",
    "        'image/object/parts/y':\n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=y)),\n",
    "        'image/object/center/x': \n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=[c_x])),\n",
    "        'image/object/center/y': \n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=[c_y])),\n",
    "        'image/object/scale':\n",
    "        tf.train.Feature(float_list=tf.train.FloatList(value=[scale])),\n",
    "        'image/object/parts/v':\n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=v)),\n",
    "        'image/encoded':\n",
    "        _bytes_feature(content),\n",
    "        'image/filename':\n",
    "        _bytes_feature(filename.encode())\n",
    "    }\n",
    "\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d750dc",
   "metadata": {},
   "source": [
    "- 정의한 json 의 python type의 값들을 tfexample 에 사용할 수 있는 값으로 변환.\n",
    "- image 파일은 byte 로 변환. bitmap 으로 저장하게되면 파일용량이 상당히 커지기 때문에 만약 jpeg 타입이 아닌 경우 jpeg 으로 변환 후 content 로 불러서 저장. (H,W,C)\n",
    "- 각 label 값을 tf.train.Feature 로 저장. 데이터 타입에 주의.\n",
    "- 이미지는 byte 인코딩 된 값을 그대로 넣음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "712dda40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy(\n",
    "        )  # BytesList won't unpack a string from an EagerTensor.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2970870",
   "metadata": {},
   "source": [
    "## Ray\n",
    "- 파이썬을 위한 간단한 분산 어플리케이션 api \n",
    "-  https://docs.ray.io/en/latest/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e271beb",
   "metadata": {},
   "source": [
    "## 모델 학습\n",
    "- ./mpii/train.py\n",
    "- 10 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46693ca",
   "metadata": {},
   "source": [
    "![Screenshot from 2021-05-20 09-53-02](https://user-images.githubusercontent.com/60597598/118903002-bb40ae80-b951-11eb-9248-41d643df0e80.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10412fe4",
   "metadata": {},
   "source": [
    "## model test\n",
    "- ./mpii/test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5243c7",
   "metadata": {},
   "source": [
    "![Screenshot from 2021-05-20 10-02-22](https://user-images.githubusercontent.com/60597598/118903338-91d45280-b952-11eb-8160-0e52cd6a684f.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a15145c",
   "metadata": {},
   "source": [
    "![Screenshot from 2021-05-20 10-01-36](https://user-images.githubusercontent.com/60597598/118903358-9c8ee780-b952-11eb-846a-4bbbfa06c502.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac888192",
   "metadata": {},
   "source": [
    "![Screenshot from 2021-05-20 10-04-50](https://user-images.githubusercontent.com/60597598/118903494-e11a8300-b952-11eb-92e6-087ee6f92e88.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed5a75f",
   "metadata": {},
   "source": [
    "# 마치며...\n",
    "- pose estimation 이 난이도가 높다는 것을 알 수 있었다. 그리고 학습 시간도 오래걸렸다. 학습시간때문에 10epochs 밖에 못돌려봤는데 다음에는 좀더 학습시켜보고 싶다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f1fc3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
