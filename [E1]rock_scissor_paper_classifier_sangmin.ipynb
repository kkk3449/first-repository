{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [E1]rock_scissor_paper_classifier_sangmin   \n",
    "이 classifier는 사람 손으로 가위바위보 모양을 만든 28x28x3 size 컬러이미지를 가위바위보 중에 무엇인지 분류한다. data_set은 가위 이미지 2400장, 바위 이미지 2400장, 보 이미지 2400장, 총 7200장 이다. train_set은 가위 이미지 200장, 바위 이미지 200장, 보 이미지 200장 총 600장 이다.   \n",
    "이미지 데이터 수집 및 분리는 aiffel_slack에서 다운받은 뒤 각각 이름을 바꿔주고 resize했다. 그리고 전체 이미지 7800장 모두 섞여있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#딥러닝 라이브러리\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "#행렬\n",
    "import numpy as np\n",
    "#파일 업로드\n",
    "import os, glob\n",
    "#그래프, 이미지 보기\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. train_dataset과 test_dataset을 불러오기 및 라벨링 함수 설계 \n",
    "총 *7200*개의 train_dataset과 *600*개의 test_dataset을 폴더에서 불러와서 numpy 행렬에 저장한다. 이미지 사이즈는 28x28x3 이다. 그리고 가위는 0, 바위는 1, 보는 2로 라벨링한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=7200   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "def test_load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=600   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_test)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 이미지 확인   \n",
    "train_dataset 라벨링 함수를 실행하고 이미지를 잘 가져왔는지 plt라이브러리를 활용하여 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 7200 입니다.\n",
      "label = 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "\n",
    "plt.imshow(x_train[2400])\n",
    "print(\"label =\", y_train[2400])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 정규화   \n",
    "test_dataset 라벨링 함수를 실행하고 train_dataset과 test_dataset 데이터 값을 255로 전부 나누어 정규화한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_test)의 이미지 개수는 600 입니다.\n"
     ]
    }
   ],
   "source": [
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "\n",
    "test_image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper_test\"\n",
    "(x_test, y_test)=test_load_data(test_image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 모델 설계   \n",
    "구글링 해보니 channel을 3개 써서 점차 증가하는 수를 넣어 주는 것이 보편적이였다. channel을 2개 쓰는 것보다 3개 쓰는 것이 결과가 좋았다. 그리고 dense 값은 20 ~ 512 사이의 값을 바꿔가며 줘봤지만 30일 때 결과가 좋았다. n_train_epoch은 20,30,50으로 해봤는데 50은 너무 오버피팅 되는 느낌이고 30이 적당했다. batch_size는 원래 기본 32로 돼있는데 이를 8로 낮추어 한번에 많이 넣었다. train_dataset이 좀 적다고 느껴져 8로 낮추었다. softmax dense 값은 가위, 바위, 보 3가지를 분류하는 것이기때문에 3을 넣어줘야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 30)                3870      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 93        \n",
      "=================================================================\n",
      "Total params: 97,211\n",
      "Trainable params: 97,211\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#바꿔 볼 수 있는 하이퍼파라미터들\n",
    "n_channel_1 = 32\n",
    "n_channel_2 = 64\n",
    "n_channel_3 = 128\n",
    "n_dense = 30\n",
    "n_train_epoch = 30\n",
    "n_train_batch_size = 8\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(n_channel_3, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. 모델 학습   \n",
    "epochs 30, batch_size 8 로 지정해주고 학습 시켰다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.9806 - accuracy: 0.4687\n",
      "Epoch 2/30\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.4656 - accuracy: 0.8149\n",
      "Epoch 3/30\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.2278 - accuracy: 0.9176\n",
      "Epoch 4/30\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.1333 - accuracy: 0.9550\n",
      "Epoch 5/30\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.1079 - accuracy: 0.9631\n",
      "Epoch 6/30\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0798 - accuracy: 0.9715\n",
      "Epoch 7/30\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0513 - accuracy: 0.9822\n",
      "Epoch 8/30\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0595 - accuracy: 0.9808\n",
      "Epoch 9/30\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0536 - accuracy: 0.9834\n",
      "Epoch 10/30\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0262 - accuracy: 0.9906\n",
      "Epoch 11/30\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0189 - accuracy: 0.9937\n",
      "Epoch 12/30\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0753 - accuracy: 0.9762\n",
      "Epoch 13/30\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0308 - accuracy: 0.9915\n",
      "Epoch 14/30\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0161 - accuracy: 0.9955\n",
      "Epoch 15/30\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0087 - accuracy: 0.9972\n",
      "Epoch 16/30\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0539 - accuracy: 0.9821\n",
      "Epoch 17/30\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0206 - accuracy: 0.9938\n",
      "Epoch 18/30\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0126 - accuracy: 0.9949\n",
      "Epoch 19/30\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0366 - accuracy: 0.9903\n",
      "Epoch 20/30\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0064 - accuracy: 0.9984\n",
      "Epoch 21/30\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0325 - accuracy: 0.9892\n",
      "Epoch 22/30\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0042 - accuracy: 0.9991\n",
      "Epoch 23/30\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0313 - accuracy: 0.9897\n",
      "Epoch 24/30\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0081 - accuracy: 0.9982\n",
      "Epoch 25/30\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0154 - accuracy: 0.9951\n",
      "Epoch 26/30\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0248 - accuracy: 0.9918\n",
      "Epoch 27/30\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0065 - accuracy: 0.9987\n",
      "Epoch 28/30\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0302 - accuracy: 0.9909\n",
      "Epoch 29/30\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 30/30\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 5.8460e-04 - accuracy: 0.9999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3e41329250>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(x_train_norm, y_train, epochs = n_train_epoch, batch_size = n_train_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. 모델 테스트   \n",
    "모델 테스트를 하고 결과 값을 출력했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 - 0s - loss: 0.5789 - accuracy: 0.9100\n",
      "test_loss: 0.5788967609405518 \n",
      "test_accuracy: 0.9100000262260437\n",
      "x_train shape: (7200, 28, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test_norm,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))\n",
    "print(\"x_train shape: {}\".format(x_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. 결론 : 정확도 91%, 손실함수 0.5789"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 후기   \n",
    "처음에 코드를 실행했을 때, 정확도는 50%는 정도였는데 loss값이 보통 300을 넘고 최소 88이였다.그래서 이미지도 더 다운받고 라벨링하고, n_channel_1, n_channel_2, n_channel_3, n_dense, n_train_epoch, n_train_batch_size 값만 주구장창 바꾸다가 soft max값이 10으로 돼어있다는 것을 5시간 만에 알고 3으로 바꿨다. 그래도 인식률만 10%정도 오르고 그대로였다. 그래서 포기하고 숙제 제출하려고 글쓰는 와중에, test_loss, test_accuracy = model.evaluate(x_test_norm,y_test, verbose=2) 이부분에 정규화 값을 안넣고 정규화 안된 값ㅠ 넣엏다는 것을 알아차렸다. 결국 다 고치고 나니 결과값이 매우 좋아서 만족했다ㅠㅠ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
